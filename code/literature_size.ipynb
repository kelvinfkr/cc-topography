{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time, resource, re, gc, shutil\n",
    "from multiprocess import Pool\n",
    "from functools import partial\n",
    "from urllib.parse import urlparse, parse_qsl\n",
    "import matplotlib\n",
    "matplotlib.use('pgf')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import django\n",
    "import pickle\n",
    "from django.db.models import Count, Sum\n",
    "sys.path.append('/home/galm/software/django/tmv/BasicBrowser/')\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "from scoping.models import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pgf_with_latex = {\n",
    "    \"text.usetex\": True,            # use LaTeX to write all text\n",
    "    \"pgf.rcfonts\": False,           # Ignore Matplotlibrc\n",
    "    \"text.latex.unicode\": True,\n",
    "    \"pgf.preamble\": [\n",
    "        #r\"\\usepackage[utf8x]{inputenc}\",\n",
    "        r\"\\usepackage{xcolor}\"\n",
    "    ],\n",
    "    \"pgf.texsystem\" : \"xelatex\",\n",
    "    \"figure.figsize\": [3.5,5]\n",
    "}\n",
    "matplotlib.rcParams.update(pgf_with_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR1</td>\n",
       "      <td>1988-1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR2</td>\n",
       "      <td>1990-1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR3</td>\n",
       "      <td>1996-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR4</td>\n",
       "      <td>2001-2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AR5</td>\n",
       "      <td>2007-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AR6</td>\n",
       "      <td>2014-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name      years\n",
       "0  AR1  1988-1989\n",
       "1  AR2  1990-1994\n",
       "2  AR3  1996-2000\n",
       "3  AR4  2001-2006\n",
       "4  AR5  2007-2013\n",
       "5  AR6      2014-"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ars = AR.objects.filter(ar__gt=0).order_by('ar').values('name','start','end')\n",
    "\n",
    "for ar in ars:\n",
    "    ar[\"years\"] = f'{ar[\"start\"]}-{ar[\"end\"]}'\n",
    "    if ar[\"name\"] == \"AR6\":\n",
    "        ar[\"years\"] = f'{ar[\"start\"]}-'\n",
    "\n",
    "ardf = pd.DataFrame.from_dict(list(ars))[['name','years']]\n",
    "\n",
    "ardf.to_latex(\"../tables/ar_years.tex\",index=False)\n",
    "#ardf['years'] = f\"-{ardf['start']}\"\n",
    "ardf.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../tables/sizes_X.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "with open(\"../tables/vecs.pickle\", \"rb\") as f:\n",
    "    vecs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<625x1380 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 9191 stored elements in Compressed Sparse Row format>,\n",
       " <7623x12409 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 478533 stored elements in Compressed Sparse Row format>,\n",
       " <16395x20453 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1270681 stored elements in Compressed Sparse Row format>,\n",
       " <34510x32644 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2818379 stored elements in Compressed Sparse Row format>,\n",
       " <117758x67064 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 10077910 stored elements in Compressed Sparse Row format>,\n",
       " <128266x74196 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 11572877 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../tables/sizes_f_X.pickle\", \"rb\") as f:\n",
    "    f_X = pickle.load(f)\n",
    "    \n",
    "with open(\"../tables/f_vecs.pickle\", \"rb\") as f:\n",
    "    f_vecs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('change', 296), ('climate', 262), ('model', 168), ('effect', 160), ('co2', 156), ('atmospheric', 152), ('climatic', 133), ('global', 131), ('greenhouse', 109), ('ocean', 106), ('temperature', 104), ('carbon', 95), ('ice', 84), ('year', 83), ('surface', 82), ('use', 81), ('sea', 80), ('water', 77), ('increase', 74), ('time', 71)]\n",
      "\n",
      "\n",
      "[('loss', 552), ('efficiency', 515), ('mol', 439), ('ambient', 417), ('coal', 404), ('photosynthetic', 393), ('concern', 381), ('chamber', 353), ('demonstrate', 351), ('consumption', 305), ('product', 299), ('throughout', 297), ('way', 297), ('combustion', 293), ('unit', 287), ('positive', 285), ('oil', 285), ('deltac', 283), ('east', 265), ('demand', 258)]\n",
      "\n",
      "\n",
      "[('downscaling', 197), ('degreesc', 145), ('ncep', 130), ('otcs', 87), ('nee', 87), ('fco', 80), ('hadcm2', 78), ('dtr', 75), ('annex', 71), ('earthworm', 60), ('boreas', 56), ('oeschger', 54), ('cdm', 51), ('opt', 50), ('reanalyses', 50), ('amip', 49), ('bracken', 49), ('msw', 48), ('bayesian', 48), ('vpd', 47)]\n",
      "\n",
      "\n",
      "[('sres', 217), ('petm', 95), ('amf', 87), ('sf5cf3', 81), ('cwd', 74), ('embankment', 72), ('aod', 69), ('clc', 69), ('1degrees', 67), ('archaeal', 67), ('tbe', 66), ('10degreesc', 63), ('15degreesc', 62), ('a1b', 58), ('25degreesc', 58), ('6degreesc', 56), ('3parts', 56), ('4parts', 56), ('amo', 55), ('1parts', 54)]\n",
      "\n",
      "\n",
      "[('biochar', 1752), ('redd', 1058), ('cmip5', 656), ('cmip3', 569), ('wrf', 334), ('mofs', 288), ('sdm', 283), ('gosat', 281), ('mof', 271), ('biochars', 252), ('aeuro', 219), ('snp', 189), ('rcp8', 183), ('et0', 165), ('nia', 162), ('zif', 160), ('rcp4', 151), ('phevs', 147), ('scco', 146), ('aoa', 142)]\n",
      "\n",
      "\n",
      "[('mmms', 192), ('c3n4', 132), ('cop21', 107), ('cmip6', 104), ('zika', 75), ('brgdgts', 71), ('twitter', 68), ('jing', 66), ('nanocatalyst', 64), ('indcs', 63), ('tcre', 61), ('esta', 60), ('puede', 60), ('gud', 60), ('cambios', 59), ('dbc', 59), ('sdg', 58), ('hadgem3', 54), ('ndcs', 54), ('orbicella', 51)]\n",
      "\n",
      "\n",
      "&\\textbf{AR1} & \\textbf{AR2} & \\textbf{AR3} & \\textbf{AR4} & \\textbf{AR5} & \\textbf{AR6}\\\\ \\hline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\\\textbf{Words} &[('change', 296), ('climate', 262), ('model', 168), ('effect', 160), ('co2', 156), ('atmospheric', 152), ('climatic', 133), ('global', 131), ('greenhouse', 109), ('ocean', 106)] & [('loss', 552), ('efficiency', 515), ('mol', 439), ('ambient', 417), ('coal', 404), ('photosynthetic', 393), ('concern', 381), ('chamber', 353), ('demonstrate', 351), ('consumption', 305)] & [('downscaling', 197), ('degreesc', 145), ('ncep', 130), ('otcs', 87), ('nee', 87), ('fco', 80), ('hadcm2', 78), ('dtr', 75), ('annex', 71), ('earthworm', 60)] & [('sres', 217), ('5degreesc', 200), ('2degreesc', 125), ('5degrees', 111), ('1degreesc', 109), ('0degreesc', 103), ('to10', 98), ('petm', 95), ('3degreesc', 88), ('4degreesc', 87)] & [('biochar', 1752), ('redd', 1058), ('cmip5', 656), ('cmip3', 569), ('wrf', 334), ('mofs', 288), ('sdm', 283), ('gosat', 281), ('mof', 271), ('biochars', 252)] & [('mmms', 192), ('c3n4', 132), ('cop21', 107), ('cmip6', 104), ('zika', 75), ('brgdgts', 71), ('twitter', 68), ('jing', 66), ('nanocatalyst', 64), ('indcs', 63)]\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocab = set()\n",
    "ignore_vocab = set([\n",
    "    'tildeo','2degreesc','5degreesc','1degreesc','0degreesc','5degrees',\n",
    "    'to10','3degreesc','4degreesc','5parts','8degreesc'\n",
    "])\n",
    "new_vocabs = []\n",
    "for i, vec in enumerate(vecs):\n",
    "    x = X[i]\n",
    "    vocab = vec.vocabulary_\n",
    "    sum_words = x.sum(axis=0).tolist()[0]\n",
    "    new_vocab = [(x[0],sum_words[x[1]]) for x in vocab.items() if x[0] not in all_vocab and x[0] not in ignore_vocab]\n",
    "    new_vocab =sorted(new_vocab, key = lambda x: x[1], reverse=True)\n",
    "    all_vocab = all_vocab | set(vec.get_feature_names()) - ignore_vocab\n",
    "    new_vocabs.append(new_vocab[:10])\n",
    "    print(new_vocab[:20])\n",
    "    print('\\n')\n",
    "\n",
    "tfmt = \" \".join([\"p{2cm}\" for x in range(7)])\n",
    "tfmt = \" \".join([\"l\" for x in range(7)])\n",
    "tfmt = \"l \" + \" \".join([\"p{1.8cm}\" for x in range(6)])\n",
    "hrow = \"&\" + \" & \".join([f\"\\\\textbf{{{x.name}}}\" for x in AR.objects.filter(ar__gt=0).order_by('ar')]) + \"\\\\\\\\ \\hline\"\n",
    "drow = \"\\\\textbf{Documents} &\" +\" & \".join([str(x.shape[0]) for x in X]) + \"\\\\\\\\ \\n\"\n",
    "wrow = \"\\\\textbf{Words} &\" +\" & \".join([str(x.shape[1]) for x in X]) + \"\\\\\\\\ \\n\"\n",
    "#nwrow = \"\\\\textbf{Words} &\" + \" & \".join([str(x) for x in new_vocabs]) \n",
    "nwrows = \"\\\\textbf{New words}\" + \"\\\\\\\\\".join([\" & \" + \" & \".join([f\"{x[i][0]} ({x[i][1]})\" for x in new_vocabs]) for i in range(8)])\n",
    "print(hrow) \n",
    "\n",
    "with open(\"../tables/growth_table.tex\",\"w\") as f:\n",
    "    f.write(\"\\\\begin{tabular}{\" + tfmt + \"} \\n\")\n",
    "    f.write(hrow)\n",
    "    f.write(drow)\n",
    "    f.write(wrow)\n",
    "    f.write(nwrows)\n",
    "    f.write(\"\\n\\\\end{tabular}\")\n",
    "## MMMs = Mixed matrix membrane\n",
    "nwrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = new_vocabs[0]\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## parse the bible, turn it into same format\n",
    "import codecs\n",
    "import re\n",
    "bible = []\n",
    "i=0\n",
    "clines=\"\"\n",
    "corpus = []\n",
    "lchapter=\"none\"\n",
    "with codecs.open('/home/galm/projects/big_literature/py/Martin_Luther_Uebersetzung_1912.txt',encoding = \"ISO-8859-1\") as ml:\n",
    "    for line in ml:\n",
    "        chapter = line.split(':')[0]\n",
    "        try:\n",
    "            verse = re.search(\".*([0-9]+\\:[0-9]*)(.*)\",line).group(2).strip()\n",
    "        except:\n",
    "            corpus.append(str(clines))\n",
    "            break\n",
    "        if lchapter!=chapter and i > 0:\n",
    "            corpus.append(str(clines))\n",
    "            clines=verse            \n",
    "        else:\n",
    "            clines+=\" \"+verse\n",
    "            #print('\\n')\n",
    "        lchapter = chapter\n",
    "        i+=1\n",
    "        \n",
    "X_y = c_vectorizer.fit_transform(corpus)\n",
    "X.append(X_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8dd3c7\n",
      "0.26106256071014744\n",
      "#ffffb3\n",
      "0.26469409500636126\n",
      "#bebada\n",
      "0.29105686163912314\n",
      "#fb8072\n",
      "0.33736081753188196\n",
      "#80b1d3\n",
      "0.41035679812605236\n",
      "#fdb462\n",
      "0.43180147447054457\n",
      "grey\n",
      "0.9392784910599727\n"
     ]
    }
   ],
   "source": [
    "ind = np.arange(1)\n",
    "\n",
    "def vvrect(X,col_x,m):\n",
    "    return plt.bar(ind+X.shape[1]/2,X.shape[0],width=X.shape[1],facecolor=col_x,edgecolor='black',alpha=m)#,alpha=m)\n",
    "\n",
    "means = [x.getnnz(0).mean()/x.shape[0]*100 for x in X]\n",
    "nmeans = normalize([means])[0]\n",
    "\n",
    "crange = ['#fbb4ae','#b3cde3','#ccebc5','#decbe4','#fed9a6','#ffffcc']\n",
    "\n",
    "crange = [\"#D53E4F\", \"#FC8D59\", \"#FEE08B\", \"#E6F598\", \"#99D594\", \"#3288BD\"]\n",
    "\n",
    "crange = [\"#8dd3c7\",\"#ffffb3\",\"#bebada\",\"#fb8072\",\"#80b1d3\",\"#fdb462\",\"grey\"]\n",
    "\n",
    "years = [x.name for x in ars] + [\"Bible\"]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plots = []\n",
    "lvalues = []\n",
    "for x in [5,4,3,2,1,0,6]:\n",
    "    a = (nmeans[x]+0.3)/1.3\n",
    "    #a = nmeans[x]\n",
    "    vvrect(X[x], \"None\",1)\n",
    "    vvrect(X[x], \"white\",1)\n",
    "    p = vvrect(X[x], crange[x] ,a)\n",
    "    plots.append(p[0])\n",
    "    lvalues.append(years[x] + \": \" + str(round(means[x],2)))\n",
    "    print(crange[5-x])\n",
    "    print(a)\n",
    "    \n",
    "plt.legend(plots,lvalues,title='% of documents mean\\nterm appears in')\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.ylabel('Documents')\n",
    "plt.xlabel('Words')\n",
    "fig.patch.set_facecolor('#f0f0f0')    \n",
    "#plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    '../plots/literature_size/volume_variety.pdf',\n",
    "    bbox_inches='tight',\n",
    "    facecolor=fig.get_facecolor(),\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>Terms</th>\n",
       "      <th>Average Document score per Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AR1</th>\n",
       "      <td>1848</td>\n",
       "      <td>2834</td>\n",
       "      <td>0.580116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR2</th>\n",
       "      <td>6941</td>\n",
       "      <td>13279</td>\n",
       "      <td>0.518233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR3</th>\n",
       "      <td>18728</td>\n",
       "      <td>26657</td>\n",
       "      <td>0.307590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR4</th>\n",
       "      <td>44000</td>\n",
       "      <td>49955</td>\n",
       "      <td>0.173971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR5</th>\n",
       "      <td>108277</td>\n",
       "      <td>92369</td>\n",
       "      <td>0.097896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR6</th>\n",
       "      <td>128357</td>\n",
       "      <td>108102</td>\n",
       "      <td>0.087417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bible</th>\n",
       "      <td>1189</td>\n",
       "      <td>10662</td>\n",
       "      <td>2.044534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Documents   Terms  Average Document score per Term\n",
       "AR1         1848    2834                         0.580116\n",
       "AR2         6941   13279                         0.518233\n",
       "AR3        18728   26657                         0.307590\n",
       "AR4        44000   49955                         0.173971\n",
       "AR5       108277   92369                         0.097896\n",
       "AR6       128357  108102                         0.087417\n",
       "Bible       1189   10662                         2.044534"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = pd.DataFrame([(x.shape[0],x.shape[1]) for x in X]).rename({0:'Documents',1:'Terms'},axis=\"columns\")\n",
    "tab.index = years\n",
    "tab['Average Document score per Term'] = means\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(-1000.0, 119102.0)\n",
      "[0]\n",
      "(-1000.0, 119102.0)\n",
      "[1, 0]\n",
      "(-1000.0, 119102.0)\n",
      "[2, 1, 0]\n",
      "(-1000.0, 119102.0)\n",
      "[3, 2, 1, 0]\n",
      "(-1000.0, 119102.0)\n",
      "[4, 3, 2, 1, 0]\n",
      "(-1000.0, 119102.0)\n",
      "[5, 4, 3, 2, 1, 0]\n",
      "(-1000.0, 119102.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shape = [(x+6000)/10000 for x in list(X[5].shape)[::1]]\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = tuple([round(x) for x in shape[::1]])\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = (9.5,13)\n",
    "\n",
    "xs = [5,4,3,2,1,0,6]\n",
    "\n",
    "for ar in AR.objects.all():\n",
    "    \n",
    "    iprs = IPCCRef.objects.filter(ar=ar).count()\n",
    "    \n",
    "    plots = []\n",
    "    lvalues = []\n",
    "\n",
    "    ar_xs = [x for x in xs if ar.ar > x ]\n",
    "    print(ar_xs)\n",
    "    #continue\n",
    "    for x in ar_xs:\n",
    "        a = (nmeans[x]+0.1)/1.1\n",
    "        #a = nmeans[x]\n",
    "        vvrect(X[x], \"None\",1)\n",
    "        vvrect(X[x], \"white\",1)\n",
    "        p = vvrect(X[x], crange[x] ,a)\n",
    "        plots.append(p[0])\n",
    "        lvalues.append(years[x] + \": \" + str(round(means[x],2)))\n",
    "        ar = AR.objects.get(ar=x+1)\n",
    "        iprs = IPCCRef.objects.filter(ar=ar).count()\n",
    "        xtent = shape[1]*10000+5000+1000\n",
    "        #plt.axhline(iprs,xmin=1/xtent*1000,xmax=1/xtent*(X[x].shape[1]+1000))\n",
    "    \n",
    "    plt.legend(plots,lvalues,title='% of documents mean term appears in')\n",
    "    \n",
    "    #plt.axis('equal')\n",
    "\n",
    "    #plt.ylim((-1000,130000))\n",
    "    #plt.ylim(ymin=-1000)\n",
    "    #plt.xlim((-1000,100000))\n",
    "    plt.xlim((-1000,shape[1]*10000+5000))\n",
    "    plt.ylim((-1000,shape[0]*10000+5000))\n",
    "    #plt.ylim(ymax=shape[0]*10000)\n",
    "    #plt.xlim(xmax=shape[1]*10000)\n",
    "    plt.ylabel('Documents')\n",
    "    plt.xlabel('Words')\n",
    "    plt.savefig('../plots/literature_size/volume_variety_{}.pdf'.format(ar.name),bbox_inches='tight')\n",
    "    \n",
    "    print(plt.xlim())\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6]\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n",
      "[1, 0, 6]\n",
      "#80b1d3\n",
      "0.30314894323988\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n",
      "[2, 1, 0, 6]\n",
      "#fb8072\n",
      "0.21688096617404234\n",
      "#80b1d3\n",
      "0.30314894323988\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n",
      "[3, 2, 1, 0, 6]\n",
      "#bebada\n",
      "0.1621581092098728\n",
      "#fb8072\n",
      "0.21688096617404234\n",
      "#80b1d3\n",
      "0.30314894323988\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n",
      "[4, 3, 2, 1, 0, 6]\n",
      "#ffffb3\n",
      "0.13100211228024514\n",
      "#bebada\n",
      "0.1621581092098728\n",
      "#fb8072\n",
      "0.21688096617404234\n",
      "#80b1d3\n",
      "0.30314894323988\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n",
      "[5, 4, 3, 2, 1, 0, 6]\n",
      "#8dd3c7\n",
      "0.12671029902108336\n",
      "#ffffb3\n",
      "0.13100211228024514\n",
      "#bebada\n",
      "0.1621581092098728\n",
      "#fb8072\n",
      "0.21688096617404234\n",
      "#80b1d3\n",
      "0.30314894323988\n",
      "#fdb462\n",
      "0.32849265164700725\n",
      "grey\n",
      "0.9282382167072406\n",
      "(-1000.0, 119102.0)\n"
     ]
    }
   ],
   "source": [
    "for ar in ars:\n",
    "    plots = []\n",
    "    lvalues = []\n",
    "\n",
    "    ar_xs = [x for x in xs if ar.ar > x or x ==6]\n",
    "    print(ar_xs)\n",
    "    #continue\n",
    "    for x in ar_xs:\n",
    "        a = (nmeans[x]+0.1)/1.1\n",
    "        #a = nmeans[x]\n",
    "        vvrect(X[x], \"None\",1)\n",
    "        vvrect(X[x], \"white\",1)\n",
    "        p = vvrect(X[x], crange[x] ,a)\n",
    "        plots.append(p[0])\n",
    "        #lvalues.append(years[x] + \": \" + str(round(X[x].mean()*1000000/X[x].sum(),5)))\n",
    "        lvalues.append(years[x] + \": \" + str(round(means[x],2)))\n",
    "        print(crange[5-x])\n",
    "        print(a)\n",
    "    \n",
    "    plt.legend(plots,lvalues,title='% of documents mean term appears in')\n",
    "    \n",
    "    #plt.axis('equal')\n",
    "\n",
    "    #plt.ylim((-1000,130000))\n",
    "    #plt.ylim(ymin=-1000)\n",
    "    #plt.xlim((-1000,100000))\n",
    "    plt.xlim((-1000,shape[1]*10000+5000))\n",
    "    plt.ylim((-1000,shape[0]*10000+5000))\n",
    "    #plt.ylim(ymax=shape[0]*10000)\n",
    "    #plt.xlim(xmax=shape[1]*10000)\n",
    "    plt.ylabel('Documents')\n",
    "    plt.xlabel('Words')\n",
    "    plt.savefig('../plots/literatures_size/volume_variety_bible_{}.pdf'.format(ar.name),bbox_inches='tight')\n",
    "    \n",
    "    print(plt.xlim())\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26134192, 0.23346384, 0.13856906, 0.07837392, 0.04410232,\n",
       "       0.03938133, 0.92106204])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means\n",
    "\n",
    "nmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.52702077667388\n",
      "0.13207462061023076\n",
      "(128357, 108102)\n",
      "\n",
      "\n",
      "\n",
      "158.94852169017744\n",
      "0.14679804731399784\n",
      "(108277, 92369)\n",
      "\n",
      "\n",
      "\n",
      "115.27574817335602\n",
      "0.2619903367576273\n",
      "(44000, 49955)\n",
      "\n",
      "\n",
      "\n",
      "87.34006077202986\n",
      "0.4663608541864046\n",
      "(18728, 26657)\n",
      "\n",
      "\n",
      "\n",
      "52.82280292190677\n",
      "0.7610258308875777\n",
      "(6941, 13279)\n",
      "\n",
      "\n",
      "\n",
      "14.361679604798871\n",
      "0.7771471647618436\n",
      "(1848, 2834)\n",
      "\n",
      "\n",
      "\n",
      "53.88051022322266\n",
      "4.531582020456069\n",
      "(1189, 10662)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in xs:\n",
    "    print(X[x].sum(0).mean())\n",
    "    print(X[x].sum(0).mean()/X[x].shape[0]*100)\n",
    "    print(X[x].shape)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.20582412906329\n",
      "0.08741698865590758\n",
      "(128357, 108102)\n",
      "\n",
      "\n",
      "\n",
      "105.99933960527883\n",
      "0.09789645040523734\n",
      "(108277, 92369)\n",
      "\n",
      "\n",
      "\n",
      "76.54727254529077\n",
      "0.17397107396656994\n",
      "(44000, 49955)\n",
      "\n",
      "\n",
      "\n",
      "57.605394455490114\n",
      "0.3075896756487084\n",
      "(18728, 26657)\n",
      "\n",
      "\n",
      "\n",
      "35.970555011672566\n",
      "0.5182330357538188\n",
      "(6941, 13279)\n",
      "\n",
      "\n",
      "\n",
      "10.720536344389556\n",
      "0.580115603051383\n",
      "(1848, 2834)\n",
      "\n",
      "\n",
      "\n",
      "24.309510410804727\n",
      "2.0445340967876136\n",
      "(1189, 10662)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in xs:\n",
    "    print(X[x].getnnz(0).mean())\n",
    "    print(X[x].getnnz(0).mean()/X[x].shape[0]*100)\n",
    "    print(X[x].shape)\n",
    "    print('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.88051022322266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y.sum(0).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmvenv_36",
   "language": "python",
   "name": "tmvenv_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
